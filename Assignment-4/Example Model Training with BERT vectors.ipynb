{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of data loading and model training with BERT vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATA_DIR = os.path.join(\"..\", \"handout\", \"data\")\n",
    "BERT_FEATURE_DIR = \"bert_output_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format training data\n",
    "\n",
    "`X` will be a matrix with `N` rows for the `N` texts in the training data, and `M` columns for the `M` features generated by BERT.\n",
    "\n",
    "`y` will be an array of `N` class labels for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(ORIGINAL_DATA_DIR, \"lang_id_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vectors = []\n",
    "with open(os.path.join(BERT_FEATURE_DIR, \"train.jsonlines\"), \"rt\") as infile:\n",
    "    for line in infile:\n",
    "        bert_data = json.loads(line)\n",
    "        for t in bert_data[\"features\"]:\n",
    "            # Only extract the [CLS] vector used for classification\n",
    "            if t[\"token\"] == \"[CLS]\":\n",
    "                # We only use the representation at the final layer of the network\n",
    "                bert_vectors.append(t[\"layers\"][0][\"values\"])\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(bert_vectors)\n",
    "y = train_df[\"native_language\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vatsa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vatsa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(penalty=\"l2\", C=1.0)\n",
    "lr_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(ORIGINAL_DATA_DIR, \"lang_id_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = []\n",
    "with open(os.path.join(BERT_FEATURE_DIR, \"test.jsonlines\"), \"rt\") as infile:\n",
    "    for line in infile:\n",
    "        bert_data = json.loads(line)\n",
    "        for t in bert_data[\"features\"]:\n",
    "            # Only extract the [CLS] vector used for classification\n",
    "            if t[\"token\"] == \"[CLS]\":\n",
    "                # We only use the representation at the final layer of the network\n",
    "                test_vectors.append(t[\"layers\"][0][\"values\"])\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(test_vectors)\n",
    "y_test = test_df[\"native_language\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy% : 45.6\n"
     ]
    }
   ],
   "source": [
    "test_labels = lr_model.predict(x_test)\n",
    "accuracy = lr_model.score(x_test, y_test)\n",
    "print(\"Accuracy% : \" + str(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predicted_language'] = test_labels\n",
    "test_df['result']=np.where(test_df['native_language'] == test_df['predicted_language'],'Yes','No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_df = test_df[test_df.native_language.isin(['Arabic'])]\n",
    "cantonese_df = test_df[test_df.native_language.isin(['Cantonese'])]\n",
    "japanese_df = test_df[test_df.native_language.isin(['Japanese'])]\n",
    "korean_df = test_df[test_df.native_language.isin(['Korean'])]\n",
    "mandarin_df = test_df[test_df.native_language.isin(['Mandarin'])]\n",
    "polish_df = test_df[test_df.native_language.isin(['Polish'])]\n",
    "russian_df = test_df[test_df.native_language.isin(['Russian'])]\n",
    "spanish_df = test_df[test_df.native_language.isin(['Spanish'])]\n",
    "thai_df = test_df[test_df.native_language.isin(['Thai'])]\n",
    "vietnamese_df = test_df[test_df.native_language.isin(['Vietnamese'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS BY CLASS: \n",
      "\n",
      "Arabic:\n",
      "Missclassification Rate: 0.515\n",
      "Precision: 0.4801980198019802\n",
      "Recall: 0.485\n",
      "Fscore: 0.4825870646766169\n",
      "\n",
      "Cantonese:\n",
      "Missclassification Rate: 0.71\n",
      "Precision: 0.30851063829787234\n",
      "Recall: 0.29\n",
      "Fscore: 0.29896907216494845\n",
      "\n",
      "Japanese:\n",
      "Missclassification Rate: 0.475\n",
      "Precision: 0.47297297297297297\n",
      "Recall: 0.525\n",
      "Fscore: 0.49763033175355453\n",
      "\n",
      "Korean:\n",
      "Missclassification Rate: 0.5800000000000001\n",
      "Precision: 0.46153846153846156\n",
      "Recall: 0.42\n",
      "Fscore: 0.4397905759162304\n",
      "\n",
      "Mandarin:\n",
      "Missclassification Rate: 0.685\n",
      "Precision: 0.3088235294117647\n",
      "Recall: 0.315\n",
      "Fscore: 0.31188118811881194\n",
      "\n",
      "Polish:\n",
      "Missclassification Rate: 0.52\n",
      "Precision: 0.4752475247524752\n",
      "Recall: 0.48\n",
      "Fscore: 0.47761194029850745\n",
      "\n",
      "Russian:\n",
      "Missclassification Rate: 0.43000000000000005\n",
      "Precision: 0.5089285714285714\n",
      "Recall: 0.57\n",
      "Fscore: 0.5377358490566037\n",
      "\n",
      "Spanish:\n",
      "Missclassification Rate: 0.5\n",
      "Precision: 0.5154639175257731\n",
      "Recall: 0.5\n",
      "Fscore: 0.5076142131979695\n",
      "\n",
      "Thai:\n",
      "Missclassification Rate: 0.41000000000000003\n",
      "Precision: 0.59\n",
      "Recall: 0.59\n",
      "Fscore: 0.59\n",
      "\n",
      "Vietnamese:\n",
      "Missclassification Rate: 0.615\n",
      "Precision: 0.4230769230769231\n",
      "Recall: 0.385\n",
      "Fscore: 0.40314136125654443\n"
     ]
    }
   ],
   "source": [
    "precision,recall,fscore,support = sklearn.metrics.precision_recall_fscore_support(test_df['native_language'], test_df['predicted_language'])\n",
    "\n",
    "print(\"METRICS BY CLASS: \\n\")\n",
    "print(\"Arabic:\")\n",
    "print(\"Missclassification Rate:\", 1-sklearn.metrics.accuracy_score(arabic_df['native_language'], arabic_df['predicted_language']))\n",
    "print(\"Precision:\", precision[0])\n",
    "print(\"Recall:\", recall[0])\n",
    "print(\"Fscore:\", fscore[0])\n",
    "\n",
    "print(\"\\nCantonese:\")\n",
    "print(\"Missclassification Rate:\", 1-sklearn.metrics.accuracy_score(cantonese_df['native_language'], cantonese_df['predicted_language']))\n",
    "print(\"Precision:\", precision[1])\n",
    "print(\"Recall:\", recall[1])\n",
    "print(\"Fscore:\", fscore[1])\n",
    "\n",
    "print(\"\\nJapanese:\")\n",
    "print(\"Missclassification Rate:\", 1-sklearn.metrics.accuracy_score(japanese_df['native_language'], japanese_df['predicted_language']))\n",
    "print(\"Precision:\", precision[2])\n",
    "print(\"Recall:\", recall[2])\n",
    "print(\"Fscore:\", fscore[2])\n",
    "\n",
    "print(\"\\nKorean:\")\n",
    "print(\"Missclassification Rate:\", 1-sklearn.metrics.accuracy_score(korean_df['native_language'], korean_df['predicted_language']))\n",
    "print(\"Precision:\", precision[3])\n",
    "print(\"Recall:\", recall[3])\n",
    "print(\"Fscore:\", fscore[3])\n",
    "\n",
    "\n",
    "print(\"\\nMandarin:\")\n",
    "print(\"Missclassification Rate:\", 1-sklearn.metrics.accuracy_score(mandarin_df['native_language'], mandarin_df['predicted_language']))\n",
    "print(\"Precision:\", precision[4])\n",
    "print(\"Recall:\", recall[4])\n",
    "print(\"Fscore:\", fscore[4])\n",
    "\n",
    "print(\"\\nPolish:\")\n",
    "print(\"Missclassification Rate:\", 1-sklearn.metrics.accuracy_score(polish_df['native_language'], polish_df['predicted_language']))\n",
    "print(\"Precision:\", precision[5])\n",
    "print(\"Recall:\", recall[5])\n",
    "print(\"Fscore:\", fscore[5])\n",
    "\n",
    "print(\"\\nRussian:\")\n",
    "print(\"Missclassification Rate:\", 1-sklearn.metrics.accuracy_score(russian_df['native_language'], russian_df['predicted_language']))\n",
    "print(\"Precision:\", precision[6])\n",
    "print(\"Recall:\", recall[6])\n",
    "print(\"Fscore:\", fscore[6])\n",
    "\n",
    "print(\"\\nSpanish:\")\n",
    "print(\"Missclassification Rate:\", 1-sklearn.metrics.accuracy_score(spanish_df['native_language'], spanish_df['predicted_language']))\n",
    "print(\"Precision:\", precision[7])\n",
    "print(\"Recall:\", recall[7])\n",
    "print(\"Fscore:\", fscore[7])\n",
    "\n",
    "print(\"\\nThai:\")\n",
    "print(\"Missclassification Rate:\", 1-sklearn.metrics.accuracy_score(thai_df['native_language'], thai_df['predicted_language']))\n",
    "print(\"Precision:\", precision[8])\n",
    "print(\"Recall:\", recall[8])\n",
    "print(\"Fscore:\", fscore[8])\n",
    "\n",
    "print(\"\\nVietnamese:\")\n",
    "print(\"Missclassification Rate:\", 1-sklearn.metrics.accuracy_score(vietnamese_df['native_language'], vietnamese_df['predicted_language']))\n",
    "print(\"Precision:\", precision[9])\n",
    "print(\"Recall:\", recall[9])\n",
    "print(\"Fscore:\", fscore[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 97   8   8  12  12  17  13  16   5  12]\n",
      " [ 10  58  14  15  48  10   8   6  14  17]\n",
      " [ 15  12 105  16   9  13   5   7  10   8]\n",
      " [  4  17  25  84  16   6  13   7  16  12]\n",
      " [ 13  40  14  14  63   7  10  12  10  17]\n",
      " [ 11   9   6   6   7  96  33  15   8   9]\n",
      " [  8  10  13   6   8  21 114  11   1   8]\n",
      " [ 18   7  14   5  12  11  18 100   6   9]\n",
      " [ 16  10   9  10   8   4   2  10 118  13]\n",
      " [ 10  17  14  14  21  17   8  10  12  77]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix determines the frequency of misscalssifications between different classes\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(test_df['native_language'], test_df['predicted_language'])\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassifications rate between each pair of classes: \n",
      " [[0.485 0.04  0.04  0.06  0.06  0.085 0.065 0.08  0.025 0.06 ]\n",
      " [0.05  0.29  0.07  0.075 0.24  0.05  0.04  0.03  0.07  0.085]\n",
      " [0.075 0.06  0.525 0.08  0.045 0.065 0.025 0.035 0.05  0.04 ]\n",
      " [0.02  0.085 0.125 0.42  0.08  0.03  0.065 0.035 0.08  0.06 ]\n",
      " [0.065 0.2   0.07  0.07  0.315 0.035 0.05  0.06  0.05  0.085]\n",
      " [0.055 0.045 0.03  0.03  0.035 0.48  0.165 0.075 0.04  0.045]\n",
      " [0.04  0.05  0.065 0.03  0.04  0.105 0.57  0.055 0.005 0.04 ]\n",
      " [0.09  0.035 0.07  0.025 0.06  0.055 0.09  0.5   0.03  0.045]\n",
      " [0.08  0.05  0.045 0.05  0.04  0.02  0.01  0.05  0.59  0.065]\n",
      " [0.05  0.085 0.07  0.07  0.105 0.085 0.04  0.05  0.06  0.385]]\n"
     ]
    }
   ],
   "source": [
    "misclassification_rate = confusion_matrix/200\n",
    "print(\"Misclassifications rate between each pair of classes: \\n\", misclassification_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
